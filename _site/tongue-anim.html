<!DOCTYPE html>
<html lang="en-US">
  <head>
  <meta charset="utf-8">
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <link href="https://fonts.googleapis.com/css?family=Gaegu:300,700" rel="stylesheet">

  <!-- Enable responsiveness on mobile devices -->
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <!-- Share card -->
  <meta name="twitter:card" content="summary" />
  <meta name="twitter:site" content="@grekogecko" />
  <meta name="twitter:creator" content="@grekogecko" />
  <meta property="og:url" content="https://salmedina.github.io/" />
  <meta property="og:title" content="Salvador Medina" />
  <meta property="og:description" content="Salvador Medina is a PhD student at Carnegie Mellon University reasearching on speech animation." />
  <meta property="og:image" content="http://salmedina.github.io/images/share.png" />

  <title>
    
      Speech Driven Tongue Animation â€” Salvador Medina
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/styles.css">
  <!-- <link rel="stylesheet" href="styles.css"> -->
  <link href="https://use.fontawesome.com/releases/v5.5.0/css/all.css" rel="stylesheet">

  <!-- Icons -->
  <link rel="apple-touch-icon" sizes="180x180" href="/icons/apple-touch-icon.png?v=xQdLjRyXLj">
  <link rel="icon" type="image/png" sizes="32x32" href="/icons/favicon-32x32.png?v=xQdLjRyXLj">
  <link rel="icon" type="image/png" sizes="16x16" href="/icons/favicon-16x16.png?v=xQdLjRyXLj">
  <link rel="manifest" href="/icons/site.webmanifest?v=xQdLjRyXLj">
  <link rel="mask-icon" href="/icons/safari-pinned-tab.svg?v=xQdLjRyXLj" color="#313131">
  <link rel="shortcut icon" href="/icons/favicon.ico?v=xQdLjRyXLj">
  <meta name="msapplication-TileColor" content="#313131">
  <meta name="msapplication-config" content="/icons/browserconfig.xml?v=xQdLjRyXLj">
  <meta name="theme-color" content="#ffffff">

  <!-- Feed -->
  <link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Salvador Medina" />

  <!-- Google Analytics -->
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-42146340-1', 'auto');
    ga('send', 'pageview');

  </script>

</head>

  <body>
    <header id="masthead">
	<h1>
  		<a href="/" title="Home">Salvador Medina</a>
  		<!-- <div class="mastheadspacer"/></div> -->
   		<!-- <span class="masthead-slash">/</span> -->
   		<!-- <small>PhD Student at Carnegie Mellon University</small> -->
	</h1>
	<nav>
		<!-- <a href="/cv">CV</a>
		<a href="/cv#publications">Publications</a>
		<a href="/everything-else">Everything Else</a> -->
	</nav>
</header>
    <main>
      <div id="paper-title-wrapper" class="l-screen">
    <h1>Speech Driven Tongue Animation</h1>
    <div id="author-wrapper">
        
            <div class="author">
                

    <!-- <a href="https://salmedina.github.io"> -->
        <img src="/images/people/salvador-medina.jpg" class="author-image">
    <!-- </a> -->


                
<a href="https://salmedina.github.io">Salvador Medina</a>
            </div>
        
            <div class="author">
                

    <!-- <a href="https://denistome.github.io/"> -->
        <img src="/images/people/denis-tome.jpg" class="author-image">
    <!-- </a> -->


                
<a href="https://denistome.github.io/">Denis Tome</a>
            </div>
        
            <div class="author">
                

    <!-- <a href="https://www.linkedin.com/in/carstenstoll"> -->
        <img src="/images/people/carsten-stoll.jpg" class="author-image">
    <!-- </a> -->


                
<a href="https://www.linkedin.com/in/carstenstoll">Carsten Stoll</a>
            </div>
        
            <div class="author">
                

    <!-- <a href="https://haskinslabs.org/people/mark-tiede"> -->
        <img src="/images/people/mark-tiede.jpg" class="author-image">
    <!-- </a> -->


                
<a href="https://haskinslabs.org/people/mark-tiede">Mark Tiede</a>
            </div>
        
            <div class="author">
                

    <!-- <a href="https://www.queensu.ca/psychology/kevin-munhall"> -->
        <img src="/images/people/kevin-munhall.jpg" class="author-image">
    <!-- </a> -->


                
<a href="https://www.queensu.ca/psychology/kevin-munhall">Kevin Munhall</a>
            </div>
        
            <div class="author">
                

    <!-- <a href="https://www.cs.cmu.edu/~alex/"> -->
        <img src="/images/people/alex-hauptmann.jpg" class="author-image">
    <!-- </a> -->


                
<a href="https://www.cs.cmu.edu/~alex/">Alex Hauptmann</a>
            </div>
        
            <div class="author">
                

    <!-- <a href="http://www.iainm.com/"> -->
        <img src="/images/people/iain-matthews.jpg" class="author-image">
    <!-- </a> -->


                
<a href="http://www.iainm.com/">Iain Matthews</a>
            </div>
        
    </div>
    <div id="venue"><i>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2022</i></div>

    
	
	
    
    

</div>


<figure class="l-middle">
    <img class="single" src="/images/papers/22-tongue-anim.png">
    <figcaption class="single"></figcaption>
</figure>


<h2>Abstract</h2>
<div><p>Advances in speech driven animation techniques now allow creating convincing animations of virtual characters solely from audio data. While many approaches focus on facial and lip motion, they often do not provide realistic animation of the inner mouth. 
Performance or motion capture of the tongue and jaw from video alone is difficult because the inner mouth is only partially observable during speech.</p>

<p>In this work, we collected a large-scale speech to tongue mocap dataset that focuses on capturing tongue, jaw, and lip motion during speech . This dataset enables research on data-driven techniques for realistic inner mouth animation. We present a method that leverages recent deep-learning based audio feature representations to build a robust and generalizable speech to animation pipeline.</p>

<p>We find that self-supervised deep learning based audio feature encoders are robust and generalize well to unseen speakers and content. To demonstrate the practical application of our approach, we show animations on a high-quality parametric 3D face model driven by the landmarks generated from our speech-to-tongue animation method.</p>
</div>


<h2>Video</h2>
<div>
  <center>
    <video source  width="426" height="240" controls playsinline>
		<source src="/videos/tongue-anim.mp4.webm" type="video/webm">
		<source src="/videos/tongue-anim.mp4.mp4" type="video/mp4">
		<source src="/videos/tongue-anim.mp4.mov" type="video/mov">
	  Ooops, it seems your browser is not capable of seeing this. Try using another browser.
    </video>
  </center>
</div>


<h2>Materials</h2>
<div id="paper-materials">


	

	
	  <a href="/tongue-anim"><div><i class="fas fa-link" aria-hidden="true"></i> Project</div></a>
	

	

	
	  <a href="/papers/Speech_Driven_Tongue_Animation__CVPR_2022.pdf"><div><i class="far fa-file-pdf" aria-hidden="true"></i> PDF</div></a>
	

	

    
      <a href="/videos/tongue-anim.mp4"><div><i class="fas fa-film" aria-hidden="true"></i> Video</div></a>
	

	

	

	

	

	

	
	  <a href="https://www.github.com/salmedina/SpeechDrivenTongueAnimation"><div><i class="fas fa-code" aria-hidden="true"></i> Code</div></a>
	

	
	  <a href="https://drive.google.com/file/d/1AkbLsj41ftc56HNPWAI-Y26-QK4Bqbo9/view?usp=sharing"><div><i class="fas fa-database" aria-hidden="true"></i> Data</div></a>
	

	

	
	

</div>

<h2>BibTeX</h2>

<div class="highlighter-rouge bibtex bibtex-wrapper">
	<div class="highlight">
		<pre>
			
@inproceedings{medina2022speechtongue,
  title={Speech Driven Tongue Animation},
  author={Medina, Salvador and Tome, Denis and Stoll, Carsten and Tiede, Mark and Munhall, Kevin and Hauptmann, Alex and Matthews, Iain},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2022},
  organization={IEEE/CVF}
}
		</pre>
	</div>
</div>


    </main>
    <footer>
	<div id="footer-left">
		<a href="mailto:salvadom@cs.cmu.edu"><i class="fa-lg fa fa-envelope footer-icon" aria-hidden="true"></i></a>
		<a href="http://www.twitter.com/grekogecko"><i class="fa-lg fab fa-twitter footer-icon" aria-hidden="true"></i></a>
		<a href="http://www.linkedin.com/in/salmedina"><i class="fa-lg fab fa-linkedin-in footer-icon" aria-hidden="true"></i></a>
		<a href="https://github.com/salmedina"><i class="fa-lg fab fa-github footer-icon" aria-hidden="true"></i></a>
		<a href="https://scholar.google.com/citations?user=Ihtg6r8AAAAJ&hl=en"><i class="fa-lg fa fa-graduation-cap footer-icon" aria-hidden="true"></i></a>
		<br>
		<br>
		&copy; <time datetime="April 22, 2022">2022</time> Salvador Medina
	</div>
	<div id="footer-right">
		Salvador Medina is a PhD student researching speech to animation for the foundations of the Metaverse.
	</div>
</footer>

  </body>
</html>
